{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--img src=\"images\\cloudflow.png\" width=1400 /-->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "\n",
    "## How to use this notebook\n",
    "This example runs Sima in locally based on input created in the [Create load case folders with unique Sima input](#loadcase_id) section. The code is only a pilot and only intended for testing. \n",
    "\n",
    "This note bookshould be run in the following way:\n",
    "1. [Installation](#installation) can be run to install all the relevant tools, like python modules and local worker executable\n",
    "2. [Initialize Workflow](#initialize), run this Python code once at every notebook start to set up basic settings. [Set up custom user parameters](#custom) section should be changed if you want to change workspace or switch between cloud and local run. 2. If you changed something in this section, remember to rerun  [Set up OneWorkflow client](#builder).\n",
    "3. [Prepare Sima Input](#prepare) sets up reading of the environment input file and build Sima input accordingly. If the input file changes OO needs to change this section.\n",
    "4. [Run analysis](#run) shall be run each time a new analysis needs to be run.\n",
    "5. [Run Wasim and Sestra](#runwasim) run Wasim and Sestra using results from above Sima run.\n",
    "\n",
    "\n",
    "### Hints\n",
    "If you get this message \"#ERROR - Error in WorkerHost: Completed, but failed to download one or more files:\", please remember the upload common file step."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize workflow <a id='initialize'></a>\n",
    "Run only once when notebook is opened."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install  <a id='installation'></a>\n",
    "Run only when packages and/or local worker  needs to be upgraded. Set _update_packages_ to True first time and when packages should be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_packages = False\n",
    "if update_packages:\n",
    "    ! pip install --index-url https://test.pypi.org/simple/ dnv-onecompute==0.1.0.527 --force-reinstall\n",
    "    ! pip install --index-url https://test.pypi.org/simple/ dnv-oneworkflow==0.1.0.527 --force-reinstall\n",
    "    ! pip install --index-url https://test.pypi.org/simple/ dnv-sesam-commands==0.1.0.527 --force-reinstall\n",
    "    \n",
    "    #! pip install --upgrade --index-url https://test.pypi.org/simple/ dnv-onecompute=0.1.0.525\n",
    "    #! pip install --upgrade --index-url https://test.pypi.org/simple/ dnv-oneworkflow=0.1.0.525\n",
    "    #! pip install - -upgrade - -index-url https: // test.pypi.org/simple / dnv-sesam-commands = 0.1.0.525\n",
    "    from oneWorkflowToolBox import *\n",
    "    await install_workflow_runtime()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up fixed user parameters <a id='fixed'></a>\n",
    "The below parameters should only be needed to modify once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sima path must be specified\n",
    "sima_exe_path = r'C:\\Program Files\\DNV\\Sima V4.4-00'         \n",
    "tempFolderPath = r\"c:\\OneWorkflowTemp\" #local directory for worker host, should be at root due to issues with long file names on Windows\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up custom user parameters <a id='custom'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local workspace, all results will be put here after local or cloud runs\n",
    "workspacePath = r'C:\\Users\\kblu\\source\\repos\\improveflowH4-workflow\\SE28ExampleSimaWasimSestra\\workspace'\n",
    "# location of common files for all analysis, has to be below workspacePath\n",
    "workspaceId = \"SE28\"\n",
    "loadcase_file = \"test_cases.xlsx\"\n",
    "wasim_input_file = \"test_cases_wasim_input.xlsx\"\n",
    "stask_file = \"SimaTemplate.stask\"\n",
    "cloud_run = False\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up OneWorkflow client <a id='builder'></a>\n",
    "Run only once workbook is started or if some parameters above are changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oneWorkflowToolBox import *\n",
    "workflow_client = one_workflow_client(\n",
    "    workspaceId, workspacePath, cloud_run, tempFolderPath)#, Platform.Linux, debug=True)\n",
    "workspace = workflow_client.one_workflow_config.workspace_config\n",
    "commonfiles_folder = workspace.common_files_directory\n",
    "results_folder = workspace.results_directory\n",
    "#If running locally the code below will also start the local workflow host.\n",
    "if (cloud_run):\n",
    "    workflow_client.login()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload common files for the job <a id='upload'></a>\n",
    "This step uploads all common files in folder *commonFilesDirectory*  to the job. Only needed to run if new common files are to be uploaded or workspace changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dnv.onecompute.directory_client import FileOptions\n",
    "try:\n",
    "    workflow_client.upload_common_files(FileOptions(\n",
    "        # max_size_bytes=124_000,\n",
    "        #patterns=[\"**/*.py\",\"**/*.inp\"],\n",
    "        overwrite=True))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Ignore this error message if the files are already present.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Sima input  <a id='prepare'></a>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create command line input for Sima\n",
    "The function below will create the command line input that will be used to run Sima. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnv.onecompute import FileSpecification\n",
    "\n",
    "\n",
    "def get_commands_inputs(\n",
    "        stask_file: str,\n",
    "        case: dict[str, Any])->dict[str, dict[str, Any]]:\n",
    "    commands = dict[str, Any]()\n",
    "    commands[\"--consoleLog\"] = \"\"\n",
    "    commands[\"--log-level\"] = \"ALL\"\n",
    "    commands[\"--data\"] = \".\"\n",
    "    commands[\"--import\"] = dict(file=FileSpecification(sharedfolder=True,\n",
    "                                directory=commonfiles_folder, filename=stask_file))\n",
    "    commands[\"--run\"] = dict(task=\"WorkflowTask\",\n",
    "                             workflow=\"ExampleWorkflow\")\n",
    "\n",
    "    return {\"commands\": commands, \"inputs\": case}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create load cases with unique Sima input <a id='loadcase_id'></a>\n",
    "This code generates the input needed for Sima for the individual load cases. The input parameters to vary in the Sima run are give in the loadcasefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dnv.sesam.sima_command import SimaCommand\n",
    "from dnv.onecompute.flowmodel import ParallelWork\n",
    "from dnv.oneworkflow import PythonCommand\n",
    "def get_parallel_work(single_task: bool = False):\n",
    "    \"\"\"Returns a parallel processing unit. If the single_task parameter is set to True, the unit will only contain the first task. \n",
    "    If set to False, all tasks will be included. The single task option is primarily used for testing purposes.\"\"\"\n",
    "    os.chdir(workspace.workspace_path)\n",
    "    load_cases_parent_folder_name = workspace.load_cases_parent_directory\n",
    "\n",
    "    parallel_work = ParallelWork()\n",
    "    parallel_work.work_items.clear()\n",
    "\n",
    "    # Open environmental input file\n",
    "    df_cases = pd.read_excel(os.path.join(workspacePath, loadcase_file), index_col=0)\n",
    "    for loadcase_folder_name, case in df_cases.iterrows():\n",
    "        load_case_folder = os.path.join(\n",
    "            load_cases_parent_folder_name, loadcase_folder_name)\n",
    "        result_folder_lc = os.path.join(workspace.results_directory, loadcase_folder_name)\n",
    "        # Get SIMA commands and inputs \n",
    "        commands_inputs = get_commands_inputs(\n",
    "             stask_file,  case.to_dict()\n",
    "        )\n",
    "        test_command = PythonCommand(\n",
    "            directory=commonfiles_folder,\n",
    "            filename=\"test.py\",\n",
    "            working_dir=loadcase_folder_name,\n",
    "        )\n",
    "        # Create SimaCommand instance\n",
    "        sima_cmd = SimaCommand(sima_exe_path)\n",
    "        sima_cmd.commands = commands_inputs[\"commands\"]\n",
    "        sima_cmd.input = commands_inputs[\"inputs\"]\n",
    "        sima_cmd.sima_result_files =[\n",
    "                \"*-sima.lis\",\n",
    "                \"variable*.inp\",\n",
    "                \"*.log\",\n",
    "                \"results.tda\",\n",
    "                \"results.txt\",\n",
    "                \"sima_*.res\",\n",
    "                \"sys-sima.dat\",\n",
    "                \"sima_*.bin\",\n",
    "                \"key_sima_*.txt\",\n",
    "                \"sima.*\"\n",
    "            ]\n",
    "        sima_cmd.working_directory = load_case_folder\n",
    "\n",
    "        # Add work item to ParallelWork instance\n",
    "        parallel_work.add(sima_cmd, work_unit_id=loadcase_folder_name+\"_ID\").output_directory(result_folder_lc,\n",
    "                                                                                         include_files=[\"**/sima*\",\"**/*.txt\", \"**/*.lis\", \"**/*.log\"])\n",
    "        if single_task == True:\n",
    "            break\n",
    "    return parallel_work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run analysis <a id='run'></a>\n",
    "This code will fetch data from the blob storage created in the step above, and run all the job tasks. The code will wait for all tasks to complete before downloading the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oneWorkflowToolBox import run_workflow_async\n",
    "import json\n",
    "\n",
    "\"\"\"Tests SIMA and Python commands\"\"\"\n",
    "# Upload Input Files\n",
    "workflow_client.upload_input_files()\n",
    "\n",
    "# Create Parallel Work Unit and Job\n",
    "work_unit = get_parallel_work()\n",
    "job = workflow_client.create_job(work_unit)\n",
    "\n",
    "job_json = json.dumps(job, default=lambda o: o.encode(), indent=4)\n",
    "#print(job_json)\n",
    "# Run workflow\n",
    "await run_workflow_async(job, workflow_client)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Wasim and Sestra <a id='runwasim'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnv.oneworkflow import PythonCommand, CompositeExecutableCommand\n",
    "from dnv.sesam.wasim_command import WasimStruCommand,  WasimSetupCommand\n",
    "from dnv.onecompute.flowmodel import WorkUnit\n",
    "from SesamUtilities import WasimAndSestraTaskCreator\n",
    "import pandas as pd\n",
    "from dnv.oneworkflow import  ParallelWork\n",
    "from oneWorkflowToolBox import Platform\n",
    "import json\n",
    "import os\n",
    "from dnv.sesam.sestra_command import SestraCommand\n",
    "workspace.results_directory = \"Results\"\n",
    "load_cases = [\"test001\"]#, \"test002\", \"test003\"]\n",
    "\n",
    "os.chdir(workspacePath)\n",
    "topSuperElement = 3\n",
    "# due to 5 field width on Sestra cards we need to use as short name here\n",
    "additionalTemplateParameters = {\n",
    "    'FMT': topSuperElement, 'topsel': topSuperElement}\n",
    "\n",
    "def run_wasim_and_sestra_using_results_from_sima(\n",
    "        results_directory: str, load_cases: str) -> ParallelWork:\n",
    "    \"\"\"Creates a parallel work unit\"\"\"\n",
    "    df_cases = pd.read_excel(os.path.join(\n",
    "        workspacePath, wasim_input_file), index_col=0)\n",
    "    parallel_work_units = list[WorkUnit]()\n",
    "\n",
    "    for casename, case in df_cases.iterrows():\n",
    "        if not casename in load_cases:\n",
    "            print(\"skipping \" + casename)\n",
    "            continue\n",
    "        \n",
    "        load_case_result_files_dir = os.path.join(results_directory, casename)\n",
    "        #For testing\n",
    "        #python_copy_command = PythonCommand(\n",
    "        #    directory=commonfiles_folder,\n",
    "        #    filename=\"copyfiles.py\",\n",
    "        #    working_dir=load_case_result_files_dir)\n",
    "        casedict = case.to_dict()\n",
    "        \n",
    "        cmd = WasimAndSestraTaskCreator(\n",
    "            load_case_result_files_dir, commonfiles_folder, casedict, additionalTemplateParameters).CreateTasks()\n",
    "        work_unit = (\n",
    "            WorkUnit(cmd, f\"post_rerun_{casename}\")\n",
    "            .input_directory(load_case_result_files_dir)\n",
    "            .output_directory(load_case_result_files_dir, include_files=[\"**/sima.*\", \"**/*.txt\", \"**/*.tda\", \"**/*.bin\", \"**/*.log\", \"**/*.inp\", \"**/*.lis\", \"**/*.mlg\", \"**/*.sin\"])\n",
    "        )\n",
    "        parallel_work_units.append(work_unit)\n",
    "\n",
    "    return ParallelWork(parallel_work_units)\n",
    "print(os.getcwd())\n",
    "print(workflow_client.workspace_path)\n",
    "\n",
    "work_unit = run_wasim_and_sestra_using_results_from_sima(\n",
    "    workspace.results_directory, load_cases)\n",
    "if not cloud_run:\n",
    "    workflow_client.upload_common_files()\n",
    "    workflow_client.upload_result_files()\n",
    "print(workflow_client.temp_path)\n",
    "\n",
    "\n",
    "downloadOptions = FileOptions(\n",
    "    max_size_bytes=11124_000,\n",
    "    patterns=[\"**/*.txt\", \"**/*.lis\", \"**/*.mlg\", \"**/*.sin\"])\n",
    "await workflow_client.run_workflow_async(\n",
    "    work_unit,\n",
    "    work_item_status_changed=work_item_status_changed_callback(workflow_client, downloadOptions),\n",
    "    log_job=True\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3f4950b6ecc2246e9f46f113f926a9a268224216b0af4259a912530ba1db262"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
