{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--img src=\"images\\cloudflow.png\" width=1400 /-->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "\n",
    "## How to use this notebook\n",
    "This example runs Sima in locally based on input created in the [Create load case folders with unique Sima input](#loadcase_id) section. The code is only a pilot and only intended for testing. \n",
    "\n",
    "This note bookshould be run in the following way:\n",
    "1. [Installation](Â£installation) can be run to install all the relevant tools, like python modules and local worker executable\n",
    "2. [Initialize Workflow](#initialize), run this Python code once at every notebook start to set up basic settings. [Set up custom user parameters](#custom) section should be changed if you want to change workspace or switch between cloud and local run. 2. If you changed something in this section, remember to rerun  [Set up OneWorkflow client](#builder).\n",
    "3. [Prepare Sima Input](#prepare) sets up reading of the environment input file and build Sima input accordingly. If the input file changes OO needs to change this section.\n",
    "4. [Run analysis](#run) shall be run each time a new analysis needs to be run.\n",
    "5. [Run Wasim and Sestra](#runwasim) run Wasim and Sestra using results from above Sima run.\n",
    "\n",
    "\n",
    "## Hints\n",
    "If you get this message \"#ERROR - Error in WorkerHost: Completed, but failed to download one or more files:\", please remember the upload common file step."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize workflow <a id='initialize'></a>\n",
    "Run only once when notebook is opened."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install or upgrade needed Python packages <a id='installation'></a>\n",
    "Run only when packages and/or local worker  needs to be upgraded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://test.pypi.org/simple/\n",
      "Collecting dnv-onecompute==0.1.0.527\n",
      "  Using cached https://test-files.pythonhosted.org/packages/58/c7/e34f974f924472c6f203deedb644048068fe1fdbf3f077a91af513ad566d/dnv_onecompute-0.1.0.527-py3-none-any.whl (32 kB)\n",
      "Collecting msal (from dnv-onecompute==0.1.0.527)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/a4/9e/7b2278305feab76061245761000046b9493ce687e97c82550c4e2e6a30d1/msal-1.22.0-py2.py3-none-any.whl (90 kB)\n",
      "Collecting azure-storage-blob (from dnv-onecompute==0.1.0.527)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/3e/84/610f379b46d7d3c2d48eadeed6a12b6d46a43100fea70534f5992d0ac996/azure_storage_blob-2.1.0-py2.py3-none-any.whl (88 kB)\n",
      "Collecting cancel-token (from dnv-onecompute==0.1.0.527)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/89/40/6e70d6e17dccbcb36b430a3af26c7b301e902f4b8784bdb542494eea51e7/cancel_token-0.1.3-py3-none-any.whl (3.3 kB)\n",
      "INFO: pip is looking at multiple versions of dnv-onecompute to determine which version is compatible with other requirements. This could take a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\kblu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement asyncio (from dnv-onecompute) (from versions: none)\n",
      "ERROR: No matching distribution found for asyncio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://test.pypi.org/simple/\n",
      "Collecting dnv-oneworkflow==0.1.0.527\n",
      "  Using cached https://test-files.pythonhosted.org/packages/aa/2c/f028b357afa90b10f624cb8d2dfce5edda99a72e41b19725a8c8f1a2ebe7/dnv_oneworkflow-0.1.0.527-py3-none-any.whl (24 kB)\n",
      "Collecting dnv-onecompute (from dnv-oneworkflow==0.1.0.527)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/58/c7/e34f974f924472c6f203deedb644048068fe1fdbf3f077a91af513ad566d/dnv_onecompute-0.1.0.527-py3-none-any.whl (32 kB)\n",
      "Collecting msal (from dnv-onecompute->dnv-oneworkflow==0.1.0.527)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/a4/9e/7b2278305feab76061245761000046b9493ce687e97c82550c4e2e6a30d1/msal-1.22.0-py2.py3-none-any.whl (90 kB)\n",
      "Collecting azure-storage-blob (from dnv-onecompute->dnv-oneworkflow==0.1.0.527)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/3e/84/610f379b46d7d3c2d48eadeed6a12b6d46a43100fea70534f5992d0ac996/azure_storage_blob-2.1.0-py2.py3-none-any.whl (88 kB)\n",
      "Collecting cancel-token (from dnv-onecompute->dnv-oneworkflow==0.1.0.527)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/89/40/6e70d6e17dccbcb36b430a3af26c7b301e902f4b8784bdb542494eea51e7/cancel_token-0.1.3-py3-none-any.whl (3.3 kB)\n",
      "INFO: pip is looking at multiple versions of dnv-onecompute to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting dnv-onecompute (from dnv-oneworkflow==0.1.0.527)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/06/99/bf53a101a47ebd859ba36399b19d51b293ff296cdd9cfe8247ce45bb63f8/dnv_onecompute-0.1.0.525-py3-none-any.whl (32 kB)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/ad/74/d8f28fdced70b895d4d4b4fbe0fedeacbb0699c8581079cc33147f675e67/dnv_onecompute-0.1.0.517-py3-none-any.whl (32 kB)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/d7/aa/af006753f95920af742782d4ce1cbd961791a58325b2069cd287e243bde2/dnv_onecompute-0.1.0.514-py3-none-any.whl (32 kB)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/70/49/1dd7fad56c00aed849771c33a899f1945e0c5a84877c8a3aa9a0c47f794d/dnv_onecompute-0.1.0.511-py3-none-any.whl (32 kB)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/1e/40/7ca66cb6bc38850c2818b4a49adc3a712ef15759f148766a55d2726c36f2/dnv_onecompute-0.1.0.508-py3-none-any.whl (32 kB)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/66/1e/eb756331ef2709070606ffebb4745c9b7e0d5bd09766e12f42a12433884e/dnv_onecompute-0.1.0.489-py3-none-any.whl (31 kB)\n",
      "\n",
      "The conflict is caused by:\n",
      "    dnv-onecompute 0.1.0.527 depends on asyncio\n",
      "    dnv-onecompute 0.1.0.525 depends on asyncio\n",
      "    dnv-onecompute 0.1.0.517 depends on asyncio\n",
      "    dnv-onecompute 0.1.0.514 depends on asyncio\n",
      "    dnv-onecompute 0.1.0.511 depends on asyncio\n",
      "    dnv-onecompute 0.1.0.508 depends on asyncio\n",
      "    dnv-onecompute 0.1.0.489 depends on asyncio\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\kblu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "ERROR: Cannot install dnv-oneworkflow because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n",
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\kblu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "ERROR: Cannot install dnv-oneworkflow because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n",
      "ERROR: Failed to install as the directory 'C:\\Users\\kblu\\AppData\\Local\\OneCompute\\LocalWorkflowRuntime' is locked by another process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://test.pypi.org/simple/\n",
      "Collecting dnv-sesam-commands==0.1.0.527\n",
      "  Using cached https://test-files.pythonhosted.org/packages/d9/56/f5024b6f08175473186bf89d358762d282a7f76f729b5bf82a6002614797/dnv_sesam_commands-0.1.0.527-py3-none-any.whl (6.5 kB)\n",
      "Collecting dnv-oneworkflow (from dnv-sesam-commands==0.1.0.527)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/aa/2c/f028b357afa90b10f624cb8d2dfce5edda99a72e41b19725a8c8f1a2ebe7/dnv_oneworkflow-0.1.0.527-py3-none-any.whl (24 kB)\n",
      "Collecting dnv-onecompute (from dnv-oneworkflow->dnv-sesam-commands==0.1.0.527)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/58/c7/e34f974f924472c6f203deedb644048068fe1fdbf3f077a91af513ad566d/dnv_onecompute-0.1.0.527-py3-none-any.whl (32 kB)\n",
      "Collecting msal (from dnv-onecompute->dnv-oneworkflow->dnv-sesam-commands==0.1.0.527)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/a4/9e/7b2278305feab76061245761000046b9493ce687e97c82550c4e2e6a30d1/msal-1.22.0-py2.py3-none-any.whl (90 kB)\n",
      "Collecting azure-storage-blob (from dnv-onecompute->dnv-oneworkflow->dnv-sesam-commands==0.1.0.527)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/3e/84/610f379b46d7d3c2d48eadeed6a12b6d46a43100fea70534f5992d0ac996/azure_storage_blob-2.1.0-py2.py3-none-any.whl (88 kB)\n",
      "Collecting cancel-token (from dnv-onecompute->dnv-oneworkflow->dnv-sesam-commands==0.1.0.527)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/89/40/6e70d6e17dccbcb36b430a3af26c7b301e902f4b8784bdb542494eea51e7/cancel_token-0.1.3-py3-none-any.whl (3.3 kB)\n",
      "INFO: pip is looking at multiple versions of dnv-onecompute to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting dnv-onecompute (from dnv-oneworkflow->dnv-sesam-commands==0.1.0.527)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/06/99/bf53a101a47ebd859ba36399b19d51b293ff296cdd9cfe8247ce45bb63f8/dnv_onecompute-0.1.0.525-py3-none-any.whl (32 kB)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/ad/74/d8f28fdced70b895d4d4b4fbe0fedeacbb0699c8581079cc33147f675e67/dnv_onecompute-0.1.0.517-py3-none-any.whl (32 kB)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/d7/aa/af006753f95920af742782d4ce1cbd961791a58325b2069cd287e243bde2/dnv_onecompute-0.1.0.514-py3-none-any.whl (32 kB)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/70/49/1dd7fad56c00aed849771c33a899f1945e0c5a84877c8a3aa9a0c47f794d/dnv_onecompute-0.1.0.511-py3-none-any.whl (32 kB)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/1e/40/7ca66cb6bc38850c2818b4a49adc3a712ef15759f148766a55d2726c36f2/dnv_onecompute-0.1.0.508-py3-none-any.whl (32 kB)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/66/1e/eb756331ef2709070606ffebb4745c9b7e0d5bd09766e12f42a12433884e/dnv_onecompute-0.1.0.489-py3-none-any.whl (31 kB)\n",
      "Collecting dnv-oneworkflow (from dnv-sesam-commands==0.1.0.527)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/28/6c/a154efdc62a24e95af5c7dbc89aa4291398abd7c1f152f95ad5b925cf813/dnv_oneworkflow-0.1.0.525-py3-none-any.whl (24 kB)\n",
      "INFO: pip is looking at multiple versions of dnv-onecompute to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached https://test-files.pythonhosted.org/packages/a9/6d/1077a44e0434c9286ae98279b9579705b3ea207bafb6f20487bdd5da5e5b/dnv_oneworkflow-0.1.0.517-py3-none-any.whl (23 kB)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/79/39/7011c8270d1fd226191582be9daef0d37d29c54368dad6c04d9e37a07c9d/dnv_oneworkflow-0.1.0.514-py3-none-any.whl (23 kB)\n",
      "  Using cached https://test-files.pythonhosted.org/packages/13/fa/8e3e666118784ade4f004e7b9544648fa43fcda6046ce88b6e1621376257/dnv_oneworkflow-0.1.0.511-py3-none-any.whl (23 kB)\n",
      "\n",
      "The conflict is caused by:\n",
      "    dnv-onecompute 0.1.0.527 depends on asyncio\n",
      "    dnv-onecompute 0.1.0.525 depends on asyncio\n",
      "    dnv-onecompute 0.1.0.517 depends on asyncio\n",
      "    dnv-onecompute 0.1.0.514 depends on asyncio\n",
      "    dnv-onecompute 0.1.0.511 depends on asyncio\n",
      "    dnv-onecompute 0.1.0.508 depends on asyncio\n",
      "    dnv-onecompute 0.1.0.489 depends on asyncio\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "update_packages = False\n",
    "if update_packages:\n",
    "    ! pip install --index-url https://test.pypi.org/simple/ dnv-onecompute==0.1.0.527 --force-reinstall\n",
    "    ! pip install --index-url https://test.pypi.org/simple/ dnv-oneworkflow==0.1.0.527 --force-reinstall\n",
    "    ! pip install --index-url https://test.pypi.org/simple/ dnv-sesam-commands==0.1.0.527 --force-reinstall\n",
    "    \n",
    "    #! pip install --upgrade --index-url https://test.pypi.org/simple/ dnv-onecompute=0.1.0.525\n",
    "    #! pip install --upgrade --index-url https://test.pypi.org/simple/ dnv-oneworkflow=0.1.0.525\n",
    "    #! pip install - -upgrade - -index-url https: // test.pypi.org/simple / dnv-sesam-commands = 0.1.0.525\n",
    "    from oneWorkflowToolBox import *\n",
    "    await install_workflow_runtime()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up fixed user parameters <a id='fixed'></a>\n",
    "The below parameters should only be needed to modify once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sima path must be specified\n",
    "sima_exe_path = r'C:\\Program Files\\DNV\\Sima V4.4-00'         \n",
    "tempFolderPath = r\"c:\\OneWorkflowTemp\" #local directory for worker host, should be at root due to issues with long file names on Windows\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up custom user parameters <a id='custom'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local workspace, all results will be put here after local or cloud runs\n",
    "workspacePath = r'C:\\Users\\kblu\\source\\repos\\improveflowH4-workflow\\SE28ExampleSimaWasimSestra\\workspace'\n",
    "# location of common files for all analysis, has to be below workspacePath\n",
    "workspaceId = \"SE28\"\n",
    "loadcase_file = \"test_cases.xlsx\"\n",
    "wasim_input_file = \"test_cases_wasim_input.xlsx\"\n",
    "stask_file = \"SimaTemplate.stask\"\n",
    "cloud_run = False\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up OneWorkflow client <a id='builder'></a>\n",
    "Run only once workbook is started or if some parameters above are changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The temporary blob storage directory is: c:\\OneWorkflowTemp\\oc_y921kny5_blob\n",
      "The temporary jobs root directory is: c:\\OneWorkflowTemp\\oc_rfc8zvwa_jobs\n",
      "c:\\OneWorkflowTemp\n"
     ]
    }
   ],
   "source": [
    "from oneWorkflowToolBox import *\n",
    "workflow_client = one_workflow_client(\n",
    "    workspaceId, workspacePath, cloud_run, tempFolderPath)#, Platform.Linux, debug=True)\n",
    "workspace = workflow_client.one_workflow_config.workspace_config\n",
    "commonfiles_folder = workspace.common_files_directory\n",
    "results_folder = workspace.results_directory\n",
    "#If running locally the code below will also start the local workflow host.\n",
    "if (cloud_run):\n",
    "    workflow_client.login()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload common files for the job <a id='upload'></a>\n",
    "This step uploads all common files in folder *commonFilesDirectory*  to the job. Only needed to run if new common files are to be uploaded or workspace changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [WinError 10061] No connection could be made because the target machine actively refused it. Failed to upload files from C:\\Users\\kblu\\source\\repos\\improveflowH4-workflow\\SE28ExampleSimaWasimSestra\\workspace\\CommonFiles.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dnv.onecompute.directory_client import FileOptions\n",
    "try:\n",
    "    workflow_client.upload_common_files(FileOptions(\n",
    "        # max_size_bytes=124_000,\n",
    "        #patterns=[\"**/*.py\",\"**/*.inp\"],\n",
    "        overwrite=True))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Ignore this error message if the files are already present.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Sima input  <a id='prepare'></a>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create command line input for Sima\n",
    "The function below will create the command line input that will be used to run Sima. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnv.onecompute import FileSpecification\n",
    "\n",
    "\n",
    "def get_commands_inputs(\n",
    "        stask_file: str,\n",
    "        case: dict[str, Any])->dict[str, dict[str, Any]]:\n",
    "    commands = dict[str, Any]()\n",
    "    commands[\"--consoleLog\"] = \"\"\n",
    "    commands[\"--log-level\"] = \"ALL\"\n",
    "    commands[\"--data\"] = \".\"\n",
    "    commands[\"--import\"] = dict(file=FileSpecification(sharedfolder=True,\n",
    "                                directory=commonfiles_folder, filename=stask_file))\n",
    "    commands[\"--run\"] = dict(task=\"WorkflowTask\",\n",
    "                             workflow=\"ExampleWorkflow\")\n",
    "\n",
    "    return {\"commands\": commands, \"inputs\": case}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create load cases with unique Sima input <a id='loadcase_id'></a>\n",
    "This code generates the input needed for Sima for the individual load cases. The input parameters to vary in the Sima run are give in the loadcasefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dnv.sesam.sima_command import SimaCommand\n",
    "from dnv.onecompute.flowmodel import ParallelWork\n",
    "from dnv.oneworkflow import PythonCommand\n",
    "def get_parallel_work(single_task: bool = False):\n",
    "    \"\"\"Returns a parallel processing unit. If the single_task parameter is set to True, the unit will only contain the first task. \n",
    "    If set to False, all tasks will be included. The single task option is primarily used for testing purposes.\"\"\"\n",
    "    os.chdir(workspace.workspace_path)\n",
    "    load_cases_parent_folder_name = workspace.load_cases_parent_directory\n",
    "\n",
    "    parallel_work = ParallelWork()\n",
    "    parallel_work.work_items.clear()\n",
    "\n",
    "    # Open environmental input file\n",
    "    df_cases = pd.read_excel(os.path.join(workspacePath, loadcase_file), index_col=0)\n",
    "    for loadcase_folder_name, case in df_cases.iterrows():\n",
    "        load_case_folder = os.path.join(\n",
    "            load_cases_parent_folder_name, loadcase_folder_name)\n",
    "        result_folder_lc = os.path.join(workspace.results_directory, loadcase_folder_name)\n",
    "        # Get SIMA commands and inputs \n",
    "        commands_inputs = get_commands_inputs(\n",
    "             stask_file,  case.to_dict()\n",
    "        )\n",
    "        test_command = PythonCommand(\n",
    "            directory=commonfiles_folder,\n",
    "            filename=\"test.py\",\n",
    "            working_dir=loadcase_folder_name,\n",
    "        )\n",
    "        # Create SimaCommand instance\n",
    "        sima_cmd = SimaCommand(sima_exe_path)\n",
    "        sima_cmd.commands = commands_inputs[\"commands\"]\n",
    "        sima_cmd.input = commands_inputs[\"inputs\"]\n",
    "        sima_cmd.sima_result_files =[\n",
    "                \"*-sima.lis\",\n",
    "                \"variable*.inp\",\n",
    "                \"*.log\",\n",
    "                \"results.tda\",\n",
    "                \"results.txt\",\n",
    "                \"sima_*.res\",\n",
    "                \"sys-sima.dat\",\n",
    "                \"sima_*.bin\",\n",
    "                \"key_sima_*.txt\",\n",
    "                \"sima.*\"\n",
    "            ]\n",
    "        sima_cmd.working_directory = load_case_folder\n",
    "\n",
    "        # Add work item to ParallelWork instance\n",
    "        parallel_work.add(sima_cmd, work_unit_id=loadcase_folder_name+\"_ID\").output_directory(result_folder_lc,\n",
    "                                                                                         include_files=[\"**/sima*\",\"**/*.txt\", \"**/*.lis\", \"**/*.log\"])\n",
    "        if single_task == True:\n",
    "            break\n",
    "    return parallel_work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run analysis <a id='run'></a>\n",
    "This code will fetch data from the blob storage created in the step above, and run all the job tasks. The code will wait for all tasks to complete before downloading the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: load cases directory C:\\Users\\kblu\\source\\repos\\improveflowH4-workflow\\SE28ExampleSimaWasimSestra\\workspace\\LoadCases does not exist.\n",
      "Error: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "[WinError 10061] No connection could be made because the target machine actively refused it\n"
     ]
    }
   ],
   "source": [
    "from oneWorkflowToolBox import run_workflow_async\n",
    "import json\n",
    "\n",
    "\"\"\"Tests SIMA and Python commands\"\"\"\n",
    "# Upload Input Files\n",
    "workflow_client.upload_input_files()\n",
    "\n",
    "# Create Parallel Work Unit and Job\n",
    "work_unit = get_parallel_work()\n",
    "job = workflow_client.create_job(work_unit)\n",
    "\n",
    "job_json = json.dumps(job, default=lambda o: o.encode(), indent=4)\n",
    "#print(job_json)\n",
    "# Run workflow\n",
    "await run_workflow_async(job, workflow_client)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Wasim and Sestra <a id='runwasim'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kblu\\source\\repos\\improveflowH4-workflow\\SE28ExampleSimaWasimSestra\\workspace\n",
      "C:\\Users\\kblu\\source\\repos\\improveflowH4-workflow\\SE28ExampleSimaWasimSestra\\workspace\n",
      "skipping test002\n",
      "skipping test003\n",
      "Error: [WinError 10061] No connection could be made because the target machine actively refused it. Failed to upload files from C:\\Users\\kblu\\source\\repos\\improveflowH4-workflow\\SE28ExampleSimaWasimSestra\\workspace\\CommonFiles.\n",
      "Error: results directory C:\\Users\\kblu\\source\\repos\\improveflowH4-workflow\\SE28ExampleSimaWasimSestra\\workspace\\Results does not exist.\n",
      "c:\\OneWorkflowTemp\n",
      "Error: [WinError 10061] No connection could be made because the target machine actively refused it\n"
     ]
    }
   ],
   "source": [
    "from dnv.oneworkflow import PythonCommand, CompositeExecutableCommand\n",
    "from dnv.sesam.wasim_command import WasimStruCommand,  WasimSetupCommand\n",
    "from dnv.onecompute.flowmodel import WorkUnit\n",
    "from SesamUtilities import WasimAndSestraTaskCreator\n",
    "import pandas as pd\n",
    "from dnv.oneworkflow import  ParallelWork\n",
    "from oneWorkflowToolBox import Platform\n",
    "import json\n",
    "import os\n",
    "from dnv.sesam.sestra_command import SestraCommand\n",
    "workspace.results_directory = \"Results\"\n",
    "load_cases = [\"test001\"]#, \"test002\", \"test003\"]\n",
    "\n",
    "os.chdir(workspacePath)\n",
    "topSuperElement = 3\n",
    "# due to 5 field width on Sestra cards we need to use as short name here\n",
    "additionalTemplateParameters = {\n",
    "    'FMT': topSuperElement, 'topsel': topSuperElement}\n",
    "\n",
    "def run_wasim_and_sestra_using_results_from_sima(\n",
    "        results_directory: str, load_cases: str) -> ParallelWork:\n",
    "    \"\"\"Creates a parallel work unit\"\"\"\n",
    "    df_cases = pd.read_excel(os.path.join(\n",
    "        workspacePath, wasim_input_file), index_col=0)\n",
    "    parallel_work_units = list[WorkUnit]()\n",
    "\n",
    "    for casename, case in df_cases.iterrows():\n",
    "        if not casename in load_cases:\n",
    "            print(\"skipping \" + casename)\n",
    "            continue\n",
    "        \n",
    "        load_case_result_files_dir = os.path.join(results_directory, casename)\n",
    "        #For testing\n",
    "        #python_copy_command = PythonCommand(\n",
    "        #    directory=commonfiles_folder,\n",
    "        #    filename=\"copyfiles.py\",\n",
    "        #    working_dir=load_case_result_files_dir)\n",
    "        casedict = case.to_dict()\n",
    "        \n",
    "        cmd = WasimAndSestraTaskCreator(\n",
    "            load_case_result_files_dir, commonfiles_folder, casedict, additionalTemplateParameters).CreateTasks()\n",
    "        work_unit = (\n",
    "            WorkUnit(cmd, f\"post_rerun_{casename}\")\n",
    "            .input_directory(load_case_result_files_dir)\n",
    "            .output_directory(load_case_result_files_dir, include_files=[\"**/sima.*\", \"**/*.txt\", \"**/*.tda\", \"**/*.bin\", \"**/*.log\", \"**/*.inp\", \"**/*.lis\", \"**/*.mlg\", \"**/*.sin\"])\n",
    "        )\n",
    "        parallel_work_units.append(work_unit)\n",
    "\n",
    "    return ParallelWork(parallel_work_units)\n",
    "print(os.getcwd())\n",
    "print(workflow_client.workspace_path)\n",
    "\n",
    "work_unit = run_wasim_and_sestra_using_results_from_sima(\n",
    "    workspace.results_directory, load_cases)\n",
    "if not cloud_run:\n",
    "    workflow_client.upload_common_files()\n",
    "    workflow_client.upload_result_files()\n",
    "print(workflow_client.temp_path)\n",
    "\n",
    "\n",
    "downloadOptions = FileOptions(\n",
    "    max_size_bytes=11124_000,\n",
    "    patterns=[\"**/*.txt\", \"**/*.lis\", \"**/*.mlg\", \"**/*.sin\"])\n",
    "await workflow_client.run_workflow_async(\n",
    "    work_unit,\n",
    "    work_item_status_changed=work_item_status_changed_callback(workflow_client, downloadOptions),\n",
    "    log_job=True\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3f4950b6ecc2246e9f46f113f926a9a268224216b0af4259a912530ba1db262"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
