{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "\n",
    "## How to use this notebook\n",
    "This example runs Sima in locally based on input created in the [Create load case folders with unique Sima input](#loadcase_id) section. The code is only a pilot and only intended for testing. \n",
    "\n",
    "This note bookshould be run in the following way:\n",
    "1. [Installation](#installation) can be run to install all the relevant tools, like python modules and local worker executable\n",
    "2. [Initialize Workflow](#initialize), run this Python code once at every notebook start to set up basic settings. [Set up custom user parameters](#custom) section should be changed if you want to change workspace or switch between cloud and local run. 2. If you changed something in this section, remember to rerun  [Set up OneWorkflow client](#builder).\n",
    "3. [Run analysis](#run) shall be run each time a new Sima analysis needs to be run.\n",
    "4. [Run Wasim and Sestra](#runwasim) run Wasim and Sestra using results from above Sima run.\n",
    "\n",
    "### Postprocessing\n",
    "It is now possible to read the SIN/FEM file using SifIO, please consult the [Python examples](https://test.pypi.org/project/dnv-sifio/) C# [documentation](https://sesam.dnv.com/dev/api/sifio/). This notebook provides a small example script for getting node coordinates and displacements for the 200 first nodes for loadcase 11, [postprocessing.py](Workspace/CommonFiles/postprocessing.py). The script will be run just after Wasim and Sestra for each load case, see the [Run Wasim and Sestra](#runwasim) section. The section [Post processing](#postprocessing) shows how the post processed result files may be read and visualized in this notebook. More Python examples will be provided later. Relevant additional documents are:\n",
    "- The input interface file documentations can be found [here](https://sesam.dnv.com/download/windows64/sesam_input_interface_format.pdf)\n",
    "- The results interface format [here](https://sesam.dnv.com/download/windows64/sesam_results_interface_format.pdf)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize workflow <a id='initialize'></a>\n",
    "Run only once when notebook is opened."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up custom user parameters <a id='custom'></a>\n",
    "You need to set oneWorkflowTMPFolder to a folder that works for you. A short folder path  is recommended due to possible issues with Sima and long file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "oneWorkflowTMPFolder = r'd:\\oneworkflowTmp' #due to possible issues with long file paths we prefer to have this folder at the root\n",
    "if not os.path.exists(oneWorkflowTMPFolder):\n",
    "    try:\n",
    "        print(\"Trying to create tmp folder for one workflow local execution\")\n",
    "        os.mkdir(oneWorkflowTMPFolder)\n",
    "        print(oneWorkflowTMPFolder + \" created!\\n\")\n",
    "    except:\n",
    "        print(\"did not manage to create tmp folder for local execution. Check that you have privileges to create it or try to manually create it from the coomand line.\")\n",
    "\n",
    "# local workspace, all results will be put here after local or cloud runs\n",
    "# location of common files for all analysis, has to be below workspacePath\n",
    "root_folder = os.getcwd()\n",
    "print(root_folder)\n",
    "workspacePath = Path(root_folder, 'Workspace')\n",
    "workspaceId = \"SE28\"\n",
    "loadcase_file = f\"{workspacePath}\\\\test_cases.xlsx\"\n",
    "wasim_input_file = \"test_cases_wasim_input.xlsx\"\n",
    "stask_file = \"SimaTemplate.stask\"\n",
    "cloudRun = False\n",
    "notebook_root_folder = os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up OneWorkflow client <a id='builder'></a>\n",
    "Run only once workbook is started or if some parameters above are changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnv.oneworkflow.utils.workunit_extension import *\n",
    "from dnv.oneworkflow.utils.starter import *\n",
    "\n",
    "workflow_client = one_workflow_client(workspace_id = workspaceId, workspace_path = workspacePath, cloud_run = cloudRun,\n",
    "                                      local_workflow_runtime_temp_folder_path = oneWorkflowTMPFolder, platform=Platform.WINDOWS, max_cores=5,auto_deploy_option = AutoDeployOption.DEV)\n",
    "workspace = workflow_client.workspace_info\n",
    "commonfiles_folder = workspace.common_files_directory\n",
    "results_folder = workspace.results_directory\n",
    "#If running locally the code below will also start the local workflow host.\n",
    "if (cloudRun):\n",
    "    workflow_client.login()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload common files for the job <a id='upload'></a>\n",
    "This step uploads all common files in folder *commonFilesDirectory*  to the job. Only needed to run if new common files are to be uploaded or workspace changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dnv.onecompute.directory_client import FileOptions\n",
    "try:\n",
    "    workflow_client.upload_common_files(FileOptions(\n",
    "        # max_size_bytes=124_000,\n",
    "        #patterns=[\"**/*.py\",\"**/*.inp\"],\n",
    "        overwrite=True))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Ignore this error message if the files are already present.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Sima analysis <a id='run'></a>\n",
    "This code will fetch data from the blob storage created in the step above, and run all the job tasks. The code will wait for all tasks to complete before downloading the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SimaHelper import *\n",
    "import json\n",
    "\"\"\"Tests SIMA and Python commands\"\"\"\n",
    "# Upload Input Files\n",
    "workflow_client.upload_input_files()\n",
    "\n",
    "#Sima path must be specified\n",
    "sima_settings = SimaSettings(sima_exe_path=r'C:\\Program Files\\DNV\\Sima V4.4-00')\n",
    "sima_work_unit = SimaTaskCreator(sima_settings, workflow_client).get_sima_work_unit(loadcase_file, stask_file)\n",
    "\n",
    "# Create Parallel Work Unit and Job\n",
    "job = workflow_client.create_job(sima_work_unit)\n",
    "job_json = json.dumps(job, default=lambda o: o.encode(), indent=4)\n",
    "\n",
    "#print(job_json)\n",
    "# Run workflow\n",
    "downloadOptions = FileOptions(\n",
    "    max_size=\"11124MB\",\n",
    "    patterns=[\"**/*.txt\", \"**/*.lis\", \"**/*.mlg\"])\n",
    "await run_workflow_async(job, workflow_client, downloadOptions)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Wasim and Sestra <a id='runwasim'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnv.onecompute.flowmodel import WorkUnit\n",
    "from SesamUtilities import WasimAndSestraTaskCreator\n",
    "import pandas as pd\n",
    "from dnv.oneworkflow import  ParallelWork\n",
    "import json\n",
    "import os\n",
    "workspace.results_directory = \"Results\"\n",
    "load_cases = [\"test001\", \"test002\"]\n",
    "\n",
    "os.chdir(workspacePath)\n",
    "topSuperElement = 3\n",
    "# due to 5 field width on Sestra cards we need to use as short name here\n",
    "additionalTemplateParameters = {\n",
    "    'FMT': topSuperElement, 'topsel': topSuperElement}\n",
    "\n",
    "def run_wasim_and_sestra_using_results_from_sima(\n",
    "        results_directory: str, load_cases: str) -> ParallelWork:\n",
    "    \"\"\"Creates a parallel work unit\"\"\"\n",
    "    df_cases = pd.read_excel(os.path.join(\n",
    "        workspacePath, wasim_input_file), index_col=0)\n",
    "    parallel_work_units = list[WorkUnit]()\n",
    "\n",
    "    for casename, case in df_cases.iterrows():\n",
    "        if not casename in load_cases:\n",
    "            print(\"skipping \" + casename)\n",
    "            continue\n",
    "        \n",
    "        load_case_result_files_dir = os.path.join(results_directory, casename)\n",
    "        casedict = case.to_dict()\n",
    "        \n",
    "        cmd = WasimAndSestraTaskCreator(\n",
    "            load_case_result_files_dir, commonfiles_folder, casedict, additionalTemplateParameters).CreateTasks()\n",
    "        work_unit = (\n",
    "            WorkUnit(cmd, f\"post_rerun_{casename}\")\n",
    "            .input_directory(load_case_result_files_dir)\n",
    "            .output_directory(load_case_result_files_dir, include_files=[\"**/sima.*\", \"**/*.txt\", \"**/*.tda\", \"**/*.bin\", \"**/*.log\", \"**/*.inp\", \"**/*.lis\", \"**/*.mlg\", \"**/*.sin\"])\n",
    "        )\n",
    "        parallel_work_units.append(work_unit)\n",
    "\n",
    "    return ParallelWork(parallel_work_units)\n",
    "print(os.getcwd())\n",
    "print(workflow_client.workspace_path)\n",
    "\n",
    "work_unit = run_wasim_and_sestra_using_results_from_sima(\n",
    "    workspace.results_directory, load_cases)\n",
    "if not cloudRun:\n",
    "    workflow_client.upload_common_files()\n",
    "    workflow_client.upload_result_files()\n",
    "\n",
    "\n",
    "downloadOptions = FileOptions(\n",
    "    min_size =0,\n",
    "    max_size= \"11124MB\",\n",
    "    patterns=[\"**/*.txt\", \"**/*.lis\", \"**/*.mlg\", \"**/*.sin\"])\n",
    "await run_workflow_async(workflow_client.create_job(work_unit), workflow_client, downloadOptions)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post processing  <a id='postprocessing'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from ipywidgets import interactive\n",
    "\n",
    "lc = 11\n",
    "dataFrames = {}\n",
    "print(workspacePath)\n",
    "for folder in glob.glob(f\"{workspacePath}\\\\Results\\\\*\"):\n",
    "    test_name = folder.split(\"\\\\\")[-1]\n",
    "    try:\n",
    "        data = np.loadtxt(f\"{folder}\\\\postprocessedresultsLC{lc}.txt\")\n",
    "        dispdata = {\n",
    "            \"x-coord\": data[:, 0],\n",
    "            \"total-disp\":  np.sqrt(data[:, 3]**2+data[:, 4]**2+data[:, 5]**2)\n",
    "        }\n",
    "        dataFrames[test_name] = pd.DataFrame(dispdata)\n",
    "    except:\n",
    "        print(\"Failed loading data for test :\" + test_name)\n",
    "\n",
    "def multiplot(resultcase):\n",
    "    dataFrames[resultcase].plot(\n",
    "        x=\"x-coord\", y=\"total-disp\", kind=\"scatter\", figsize=(15, 15))\n",
    "\n",
    "\n",
    "interactive_plot = interactive(multiplot, resultcase=dataFrames.keys())\n",
    "interactive_plot\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3f4950b6ecc2246e9f46f113f926a9a268224216b0af4259a912530ba1db262"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
