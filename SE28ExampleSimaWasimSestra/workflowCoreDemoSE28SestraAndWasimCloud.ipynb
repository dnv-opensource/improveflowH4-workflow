{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--img src=\"images\\cloudflow.png\" width=1400 /-->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "## How to use this notebook\n",
    "This example runs Sima in the cloud based on input created in the [Create load case folders with unique Sima input](#loadcase_id) section. The code is only a pilot and only intended for testing. This notebook assumes that all tooling is in place see the installation section of the notebook for [local execution](workflowCoreDemoSE28SestraAndWasim.ipynb#installation)\n",
    "\n",
    "This note book should be run in the following way:\n",
    "1. [Initialize Workflow](#initialize), run this Python code once at every notebook start to set up basic settings. [Set up custom user parameters](#custom) section should be changed if you want to change workspace or switch between cloud and local run. 2. If you changed something in this section, remember to rerun  [Set up OneWorkflow client](#builder).\n",
    "2. [Prepare Sima Input](#prepare) sets up reading of the environment input file and build Sima input accordingly. If the input file changes OO needs to change this section.\n",
    "3. [Run analysis](#run) shall be run each time a new analysis needs to be run.\n",
    "4. [Run Wasim and Sestra](#runwasim) run Wasim and Sestra using results from above Sima run.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize workflow <a id='initialize'></a>\n",
    "Run only once when notebook is opened."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up custom user parameters <a id='custom'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "oneWorkflowTMPFolder = r'd:\\oneworkflowTmp' #due to possible issues with long file paths we prefer to have this folder at the root\n",
    "if not os.path.exists(oneWorkflowTMPFolder):\n",
    "    try:\n",
    "        print(\"Trying to create tmp folder for one workflow local execution\")\n",
    "        os.mkdir(oneWorkflowTMPFolder)\n",
    "        print(oneWorkflowTMPFolder + \" created!\\n\")\n",
    "    except:\n",
    "        print(\"did not manage to create tmp folder for local execution. Check that you have privileges to create it or try to manually create it from the coomand line.\")\n",
    "\n",
    "# local workspace, all results will be put here after local or cloud runs\n",
    "# location of common files for all analysis, has to be below workspacePath\n",
    "root_folder = os.getcwd()\n",
    "print(root_folder)\n",
    "oldworkspacePath = str(Path(root_folder, 'Workspace'))\n",
    "workspacePath = str(Path(root_folder, 'WorkspaceCloud'))\n",
    "workspaceId = \"SE28\"\n",
    "loadcase_file = f\"{workspacePath}\\\\test_cases.xlsx\"\n",
    "wasim_input_file = \"test_cases_wasim_input.xlsx\"\n",
    "stask_file = \"SimaTemplate.stask\"\n",
    "cloudRun = False\n",
    "notebook_root_folder = os.getcwd()\n",
    "shutil.copytree(oldworkspacePath, workspacePath,dirs_exist_ok=True, ignore=shutil.ignore_patterns(\"LoadCases\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up OneWorkflow client <a id='builder'></a>\n",
    "Run only once workbook is started or if some parameters above are changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The temporary blob storage directory is: d:\\oneworkflowTmp\\oc_2fcm6o1i_blob\n",
      "The temporary jobs root directory is: d:\\oneworkflowTmp\\oc_ajvd4hfq_jobs\n"
     ]
    }
   ],
   "source": [
    "from dnv.oneworkflow.utils.workunit_extension import *\n",
    "from dnv.oneworkflow.utils import *\n",
    "#workflow_client = one_workflow_client(workspace_id = workspaceId, cloud_run = cloudRun, workspace_path = workspacePath, local_workflow_runtime_temp_folder_path = oneWorkflowTMPFolder,\n",
    "#                                      local_workflow_runtime_temp_folders_cleanup=False,platform=Platform.LINUX, max_cores=5,environment=Environment.Testing,pool_id=\"SesamWorkflow_Linux_Standard_A1_v2\")\n",
    "\n",
    "workflow_client = one_workflow_client(workspace_id = workspaceId, cloud_run = cloudRun, workspace_path = workspacePath, local_workflow_runtime_temp_folder_path = oneWorkflowTMPFolder,\n",
    "                                      local_workflow_runtime_temp_folders_cleanup=False,platform=Platform.WINDOWS, max_cores=5,environment=Environment.Testing,pool_id=\"SesamWorkflow_Windows_Standard_A2_v2\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run analysis <a id='run'></a>\n",
    "This code will fetch data from the blob storage created in the step above, and run all the job tasks. The code will wait for all tasks to complete before downloading the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnv.sesam.sima_command import SimaCommand\n",
    "import pandas as pd\n",
    "\"\"\"Tests SIMA and Python commands\"\"\"\n",
    "# Upload Input Files\n",
    "workflow_client.upload_input_files()\n",
    "\n",
    "commands_info = []\n",
    "\n",
    "df_cases = pd.read_excel(loadcase_file, index_col=0)\n",
    "\n",
    "for loadcase_folder_name, case in df_cases.iterrows():\n",
    "    sima_cmd = SimaCommand().create_sima_command(task_name=\"WorkflowTask\",workflow_name=\"ExampleWorkflow\",sima_case_data=case.to_dict(),stask_filename=stask_file,stask_foldername=workflow_client.common_directory)\n",
    "    commands_info.append(CommandInfo(commands=[sima_cmd],load_case_foldername=loadcase_folder_name))\n",
    "print(\"Running commands in parallel\")\n",
    "await run_managed_commands_parallelly_async(\n",
    "            log_job = True,\n",
    "            client=workflow_client,\n",
    "            commands_info=commands_info,\n",
    "            files_to_download_from_blob_to_client=FileOptions(max_size=\"11124MB\",patterns=[\"**/*.log\",\"**/*.txt\", \"**/*.lis\", \"**/*.MLG\", \"**/*.MLG\",\"**/*.CSV\"]),\n",
    "            enable_common_files_copy_to_load_cases=True,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Wasim and Sestra <a id='runwasim'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnv.oneworkflow import PythonCommand, CompositeExecutableCommand\n",
    "from dnv.sesam.wasim_command import WasimStruCommand,  WasimSetupCommand\n",
    "from dnv.sesam.sestra_command import SestraCommand\n",
    "from dnv.onecompute.flowmodel import WorkUnit\n",
    "from SesamUtilities import WasimAndSestraTaskCreator\n",
    "import pandas as pd\n",
    "from dnv.oneworkflow import  ParallelWork\n",
    "from oneWorkflowToolBox import run_workflow_async\n",
    "import json\n",
    "import os\n",
    "workspace.results_directory = \"Results\"\n",
    "load_cases = [\"test001\", \"test002\"]\n",
    "windows_client = one_workflow_client(\n",
    "    workspaceId, workspacePath, cloud_run, \"\", Platform.Windows)\n",
    "os.chdir(workspacePath)\n",
    "topSuperElement = 3\n",
    "# due to 5 field width on Sestra cards we need to use as short name here\n",
    "additionalTemplateParameters = {'FMT': topSuperElement, 'topsel': topSuperElement}\n",
    "\n",
    "def run_wasim_and_sestra_using_results_from_sima(\n",
    "        results_directory: str, load_cases: str) -> ParallelWork:\n",
    "    \"\"\"Creates a parallel work unit\"\"\"\n",
    "    df_cases = pd.read_excel(os.path.join(\n",
    "        workspacePath, wasim_input_file), index_col=0)\n",
    "    parallel_work_units = list[WorkUnit]()\n",
    "\n",
    "    for casename, case in df_cases.iterrows():\n",
    "        if not casename in load_cases:\n",
    "            print(\"skipping \" + casename)\n",
    "            continue\n",
    "\n",
    "        casedict = case.to_dict()\n",
    "       \n",
    "        load_case_result_files_dir = os.path.join(results_directory, casename)\n",
    "        cmds = WasimAndSestraTaskCreator(\n",
    "            load_case_result_files_dir, commonfiles_folder, casedict, additionalTemplateParameters).CreateTasks()\n",
    "        cmd = CompositeExecutableCommand(cmds)\n",
    "        work_unit = (\n",
    "            WorkUnit(cmd,  f\"post_rerun_{casename}\")\n",
    "            .input_directory(load_case_result_files_dir)\n",
    "            .output_directory(load_case_result_files_dir, include_files=[\"**/sima.*\", \"**/*.txt\", \"**/*.tda\", \"**/*.bin\", \"**/*.log\", \"**/*.inp\", \"**/*.lis\", \"**/*.mlg\", \"**/*.sin\"\n",
    "                                                                         ,\"**/*.LIS\", \"**/*.MLG\"])\n",
    "        )\n",
    "        parallel_work_units.append(work_unit)\n",
    "\n",
    "    return ParallelWork(parallel_work_units)\n",
    "\n",
    "from dnv.onecompute.flowmodel import WorkUnit\n",
    "from SesamUtilities import WasimAndSestraTaskCreator\n",
    "import pandas as pd\n",
    "from dnv.oneworkflow import  ParallelWork\n",
    "import json\n",
    "import os\n",
    "load_cases = [\"test001\", \"test002\"]\n",
    "\n",
    "os.chdir(workspacePath)\n",
    "topSuperElement = 3\n",
    "# due to 5 field width on Sestra cards we need to use as short name here\n",
    "additionalTemplateParameters = {\n",
    "    'FMT': topSuperElement, 'topsel': topSuperElement}\n",
    "\n",
    "def create_wasim_and_sestra_tasks(load_cases: str) -> ParallelWork:\n",
    "    \"\"\"Creates a parallel work unit\"\"\"\n",
    "    df_cases = pd.read_excel(os.path.join(\n",
    "        workspacePath, wasim_input_file), index_col=0)\n",
    "    commands_info = []\n",
    "    for casename, case in df_cases.iterrows():\n",
    "        if not casename in load_cases:\n",
    "            print(\"skipping \" + casename)\n",
    "            continue\n",
    "        \n",
    "        casedict = case.to_dict()\n",
    "        tasks = WasimAndSestraTaskCreator(casedict, additionalTemplateParameters).CreateTasks()\n",
    "        cmd_info = CommandInfo(commands=tasks,load_case_foldername=casename)\n",
    "        commands_info.append(cmd_info)\n",
    "       \n",
    "\n",
    "    return commands_info\n",
    "print(os.getcwd())\n",
    "print(workflow_client.workspace_path)\n",
    "\n",
    "windows_client.login()\n",
    "work_unit = run_wasim_and_sestra_using_results_from_sima(\n",
    "    workspace.results_directory, load_cases)\n",
    "\n",
    "downloadOptions = FileOptions(\n",
    "    #max_size_bytes=1001124_000,\n",
    "    patterns=[\"**/*.txt\", \"**/*.lis\", \"**/*.mlg\", \"**/*.sin\"])\n",
    "#await workflow_windows_client.run_workflow_async(\n",
    "#    work_unit,\n",
    "    #work_item_status_changed=work_item_status_changed_callback(\n",
    "        #workflow_windows_client, downloadOptions),\n",
    "    #log_job=True\n",
    "#)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await run_workflow_async_two_clients(\n",
    "    job, workflow_client, windows_client, work_unit, option=downloadOptions)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post processing  <a id='postprocessing'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from ipywidgets import interactive\n",
    "\n",
    "lc = 11\n",
    "dataFrames = {}\n",
    "print(workspacePath)\n",
    "for folder in glob.glob(f\"{workspacePath}\\\\Results\\\\*\"):\n",
    "    test_name = folder.split(\"\\\\\")[-1]\n",
    "    try:\n",
    "        data = np.loadtxt(f\"{folder}\\\\postprocessedresultsLC{lc}.txt\")\n",
    "        dispdata = {\n",
    "            \"x-coord\": data[:, 0],\n",
    "            \"total-disp\":  np.sqrt(data[:, 3]**2+data[:, 4]**2+data[:, 5]**2)\n",
    "        }\n",
    "        dataFrames[test_name] = pd.DataFrame(dispdata)\n",
    "    except:\n",
    "        print(\"Failed loading data for test :\" + test_name)\n",
    "\n",
    "\n",
    "def multiplot(resultcase):\n",
    "    dataFrames[resultcase].plot(\n",
    "        x=\"x-coord\", y=\"total-disp\", kind=\"scatter\", figsize=(15, 15))\n",
    "\n",
    "\n",
    "interactive_plot = interactive(\n",
    "    multiplot, resultcase=dataFrames.keys())\n",
    "interactive_plot\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3f4950b6ecc2246e9f46f113f926a9a268224216b0af4259a912530ba1db262"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
