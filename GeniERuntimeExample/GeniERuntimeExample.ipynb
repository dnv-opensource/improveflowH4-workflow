{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description \n",
    "This example demonstrates how to run GeniERuntime through OneWorkflow. A small dummy script for demonstrating SifIO is also provided. This example uses a parametrized containership model from [GeniE Snack Pack](https://sesam.dnv.com/genie_utils/hullforms/containership.html). *AP* and *FP* are parametrized and input given from a Pandas dataframe as shown below.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnv.oneworkflow.utils import *\n",
    "from pathlib import Path\n",
    "import os\n",
    "root_folder = os.getcwd()\n",
    "workspacePath = str(Path(root_folder, 'Workspace'))\n",
    "workspaceId = \"GeniERuntimeExample\"\n",
    "\n",
    "cloudRun = False\n",
    "oneWorkflowTMPFolder = r'c:\\oneworkflowTmp' #due to possible issues with long file paths we prefer to have this folder at the root\n",
    "if not os.path.exists(oneWorkflowTMPFolder):\n",
    "    try:\n",
    "        print(\"Trying to create tmp folder for one workflow local execution\")\n",
    "        os.mkdir(oneWorkflowTMPFolder)\n",
    "        print(oneWorkflowTMPFolder + \" created!\\n\")\n",
    "    except:\n",
    "        print(\"did not manage to create tmp folder for local execution. Check that you have privileges to create it or try to manually create it from the coomand line.\")\n",
    "#If running locally the code below will also start the local workflow host.\n",
    "workflow_client = one_workflow_client(workspace_id = workspaceId, cloud_run = cloudRun, workspace_path = workspacePath, local_workflow_runtime_temp_folder_path = oneWorkflowTMPFolder,\n",
    "                                      local_workflow_runtime_temp_folders_cleanup=False,environment=Environment.Testing,pool_id=\"SesamWorkflow_Windows_Standard_A2_v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "from dnv.oneworkflow import PythonCommand\n",
    "from dnv.sesam.commands import *\n",
    "# we must delete existing results locally before generating new results\n",
    "local__result_path = Path(workspacePath, workflow_client.results_directory)\n",
    "try:\n",
    "    if os.path.isdir(local__result_path):\n",
    "        shutil.rmtree(local__result_path)\n",
    "except:\n",
    "      print(\"Error while deleting the result folder\")\n",
    "\n",
    "#parametrized values\n",
    "df = pd.DataFrame({'AP':  [\"0m\", \"0.5m\", \"1m\"], 'FP': [\"150m\", \"250m\", \"500m\"]})\n",
    "#for debugging only\n",
    "#job_json = json.dumps(job, default=lambda o: o.encode(), indent=4)\n",
    "#print(job_json)\n",
    "\n",
    "\n",
    "commands_info = []\n",
    "for index, row in df.iterrows():\n",
    "            loadcase_folder_name = f\"Model_{index + 1}\"\n",
    "            genieruntime_command = GeniERuntimeCommand()\n",
    "            genieruntime_command.Parameters = {}\n",
    "            genieruntime_command.TemplateInputFile = \"ContainerHull_template.js\"\n",
    "            for key, value in row.items():\n",
    "                genieruntime_command.Parameters[key] = value\n",
    "           \n",
    "            post_processing_command = PythonCommand(\n",
    "                directory=workflow_client.common_directory,\n",
    "                filename=\"postprocessing.py\")\n",
    "            cmd_info = CommandInfo(commands=[genieruntime_command,post_processing_command],load_case_foldername=loadcase_folder_name)\n",
    "            commands_info.append(cmd_info)\n",
    "            \n",
    "print(\"Running commands in parallel\")\n",
    "await run_managed_commands_parallelly_async(\n",
    "            client=workflow_client,\n",
    "            commands_info=commands_info,\n",
    "            files_to_download_from_blob_to_client=FileTransferOptions(max_size=\"11124MB\",patterns=[\"**/*.txt\", \"**/*.lis\", \"**/*.MLG\", \"**/*.MLG\",\"**/*.CSV\",\"**/*.FEM\"]),\n",
    "            enable_common_files_copy_to_load_cases=True,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing\n",
    "The code below prints out node and element counts for the different models and present the results in a table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "lc = 11\n",
    "frames = []\n",
    "for folder in glob.glob(f\"{local__result_path}\\\\*\"):\n",
    "    data = pd.read_csv(Path(folder, \"nodeCount.csv\"), index_col=0)\n",
    "    data.index = [folder.split('\\\\')[-1]]\n",
    "    frames.append(data)\n",
    "df = pd.concat(frames)\n",
    "df=df.rename_axis(\"Loadcase\")\n",
    "display(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
