{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description \n",
    "This example demonstrates how to run GeniERuntime through OneWorkflow. A small dummy script for demonstrating SifIO is also provided. This example uses a parametrized containership model from [GeniE Snack Pack](https://sesam.dnv.com/genie_utils/hullforms/containership.html). *AP* and *FP* are parametrized and input given from a Pandas dataframe as shown below.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from oneWorkflowToolBox import *\n",
    "workspaceId = \"GeniERuntimeExample\"\n",
    "# local workspace, all results will be put here after local or cloud runs\n",
    "# location of common files for all analysis, has to be below workspacePath and in the folder names CommonFilesr\n",
    "root_folder = os.getcwd()\n",
    "print(root_folder)\n",
    "workspacePath = Path(root_folder, 'Workspace')\n",
    "cloud_run = True\n",
    "#If running locally the code below will also start the local workflow host.\n",
    "workflow_client = one_workflow_client(workspaceId, workspacePath, cloud_run, tmp=r\"c:\\OneWorkflowTemp\", platform=Platform.Windows)\n",
    "if (cloud_run):\n",
    "    workflow_client.login()\n",
    "workflow_client.upload_common_files(FileOptions(max_size_bytes=524_000,patterns=[\"**/*.*\"], overwrite=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from oneWorkflowToolBox import run_workflow_async\n",
    "from SesamHelpers import *\n",
    "import shutil\n",
    "import json\n",
    "# we must delete existing results locally before generating new results\n",
    "local__result_path = Path(workspacePath, workflow_client.results_directory)\n",
    "if os.path.isdir(local__result_path):\n",
    "    shutil.rmtree(local__result_path)\n",
    "\n",
    "#parametrized values\n",
    "df = pd.DataFrame({'AP':  [\"0m\", \"0.5m\", \"1m\"], 'FP': [\"150m\", \"250m\", \"500m\"]})\n",
    "workUnit = GeniERuntimeTaskCreator(\"ContainerHull_template.js\", df,workflow_client).get_genieruntime_work_unit(cloud_run, workspacePath)\n",
    "downloadOptions = FileOptions(\n",
    "    max_size_bytes=11124_000,\n",
    "    patterns=[\"**/T1.FEM\", \"**/*.csv\"])\n",
    "job = workflow_client.create_job(workUnit)\n",
    "\n",
    "#for debugging only\n",
    "#job_json = json.dumps(job, default=lambda o: o.encode(), indent=4)\n",
    "#print(job_json)\n",
    "await run_workflow_async(job, workflow_client, downloadOptions)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing\n",
    "The code below prints out node and element counts for the different models and present the results in a table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "lc = 11\n",
    "frames = []\n",
    "for folder in glob.glob(f\"{local__result_path}\\\\*\"):\n",
    "    data = pd.read_csv(Path(folder, \"nodeCount.csv\"), index_col=0)\n",
    "    data.index = [folder.split('\\\\')[-1]]\n",
    "    frames.append(data)\n",
    "df = pd.concat(frames)\n",
    "df=df.rename_axis(\"Loadcase\")\n",
    "display(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
