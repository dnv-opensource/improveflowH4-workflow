{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description \n",
    "This example demonstrates how to run GeniERuntime through OneWorkflow. A small dummy script for demonstrating SifIO is also provided. This example uses a parametrized containership model from [GeniE Snack Pack](https://sesam.dnv.com/genie_utils/hullforms/containership.html). *AP* and *FP* are parametrized and input given from a Pandas dataframe as shown below.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dnv.oneworkflow.utils.workunit_extension import *\n",
    "from dnv.oneworkflow.utils.starter import *\n",
    "from dnv.oneworkflow import OneWorkflowClient\n",
    "from pathlib import Path\n",
    "import os\n",
    "oneWorkflowTMPFolder = r'D:\\OneWorkflowTmp' #due to possible issues with long file paths we prefer to have this folder at the root\n",
    "if not os.path.exists(oneWorkflowTMPFolder):\n",
    "    try:\n",
    "        print(\"Trying to create tmp folder for one workflow local execution\")\n",
    "        os.mkdir(oneWorkflowTMPFolder)\n",
    "    except:\n",
    "        print(\"did not manage to create tmp folder for local execution. Check that you have privileges to create it or try to manually create it from the coomand line.\")\n",
    "\n",
    "workspaceId = \"GeniERuntimeExample\"\n",
    "# local workspace, all results will be put here after local or cloud runs\n",
    "# location of common files for all analysis, has to be below workspacePath and in the folder names CommonFilesr\n",
    "root_folder = os.getcwd()\n",
    "print(root_folder)\n",
    "workspacePath = str(Path(root_folder, 'Workspace'))\n",
    "cloudRun = False\n",
    "#If running locally the code below will also start the local workflow host.\n",
    "workflow_client = one_workflow_client(workspace_id = workspaceId, workspace_path = workspacePath, cloud_run = cloudRun,\n",
    "                                      local_workflow_runtime_temp_folder_path = oneWorkflowTMPFolder, platform=Platform.WINDOWS, max_cores=5,auto_deploy_option = AutoDeployOption.DEV)\n",
    "workflow_client.start_workflow_runtime_service()\n",
    "if (cloudRun):\n",
    "    workflow_client.login()\n",
    "if not workflow_client.upload_common_files(FileOptions(max_size=\"524MB\",patterns=[\"**/*.*\"], overwrite=True)):\n",
    "    print(\"Upload failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from SesamHelpers import *\n",
    "import shutil\n",
    "import json\n",
    "# we must delete existing results locally before generating new results\n",
    "local__result_path = Path(workspacePath, workflow_client.results_directory)\n",
    "if os.path.isdir(local__result_path):\n",
    "    shutil.rmtree(local__result_path)\n",
    "\n",
    "#parametrized values\n",
    "df = pd.DataFrame({'AP':  [\"0m\", \"0.5m\", \"1m\"], 'FP': [\"150m\", \"250m\", \"500m\"]})\n",
    "workUnit = GeniERuntimeTaskCreator(\"ContainerHull_template.js\", df,workflow_client).get_genieruntime_work_unit(cloudRun, workspacePath)\n",
    "downloadOptions = FileOptions(\n",
    "    max_size=\"1112MB\",\n",
    "    patterns=[\"**/T1.FEM\", \"**/*.csv\"])\n",
    "job = workflow_client.create_job(workUnit)\n",
    "\n",
    "#for debugging only\n",
    "#job_json = json.dumps(job, default=lambda o: o.encode(), indent=4)\n",
    "#print(job_json)\n",
    "await run_workflow_async(job, workflow_client, downloadOptions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLose client -must be done before a new job can be started in a different notebook\n",
    "Will remove all job and blob folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_client.local_workflow_runtime_service.stop_service()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing\n",
    "The code below prints out node and element counts for the different models and present the results in a table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "lc = 11\n",
    "frames = []\n",
    "for folder in glob.glob(f\"{local__result_path}\\\\*\"):\n",
    "    data = pd.read_csv(Path(folder, \"nodeCount.csv\"), index_col=0)\n",
    "    data.index = [folder.split('\\\\')[-1]]\n",
    "    frames.append(data)\n",
    "df = pd.concat(frames)\n",
    "df=df.rename_axis(\"Loadcase\")\n",
    "display(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
