{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description \n",
    "This example demonstrates how to run GeniERuntime through OneWorkflow. A small dummy script for demonstrating SifIO is also provided. This example uses a parametrized containership model from [GeniE Snack Pack](https://sesam.dnv.com/genie_utils/hullforms/containership.html). *AP* and *FP* are parametrized and input given from a Pandas dataframe as shown below.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kblu\\source\\repos\\improveflowGIT\\GeniERuntimeExample\n",
      "The temporary blob storage directory is: c:\\oneworkflowTmp\\oc_hnh_vcoh_blob\n",
      "The temporary jobs root directory is: c:\\oneworkflowTmp\\oc_ksnbh2xd_jobs\n",
      "c:\\oneworkflowTmp\n",
      "Error: [WinError 10061] No connection could be made because the target machine actively refused it. Failed to upload files from c:\\Users\\kblu\\source\\repos\\improveflowGIT\\GeniERuntimeExample\\Workspace\\CommonFiles.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from oneWorkflowToolBox import *\n",
    "oneWorlflowTMPFolder = r'c:\\oneworkflowTmp' #due to possible issues with long file paths we prefer to have this folder at the root\n",
    "if not os.path.exists(oneWorlflowTMPFolder):\n",
    "    try:\n",
    "        print(\"Trying to create tmp folder for one workflow local execution\")\n",
    "        os.mkdir(oneWorlflowTMPFolder)\n",
    "    except:\n",
    "        print(\"did not manage to create tmp folder for local execution. Check that you have privileges to create it or try to manually create it from the coomand line.\")\n",
    "\n",
    "workspaceId = \"GeniERuntimeExample\"\n",
    "# local workspace, all results will be put here after local or cloud runs\n",
    "# location of common files for all analysis, has to be below workspacePath and in the folder names CommonFilesr\n",
    "root_folder = os.getcwd()\n",
    "print(root_folder)\n",
    "workspacePath = Path(root_folder, 'Workspace')\n",
    "cloud_run = False\n",
    "#If running locally the code below will also start the local workflow host.\n",
    "workflow_client = one_workflow_client(workspaceId, workspacePath, cloud_run, tmp=oneWorlflowTMPFolder, platform=Platform.Windows)\n",
    "if (cloud_run):\n",
    "    workflow_client.login()\n",
    "workflow_client.upload_common_files(FileOptions(max_size_bytes=524_000,patterns=[\"**/*.*\"], overwrite=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from oneWorkflowToolBox import run_workflow_async\n",
    "from SesamHelpers import *\n",
    "import shutil\n",
    "import json\n",
    "# we must delete existing results locally before generating new results\n",
    "local__result_path = Path(workspacePath, workflow_client.results_directory)\n",
    "if os.path.isdir(local__result_path):\n",
    "    shutil.rmtree(local__result_path)\n",
    "\n",
    "#parametrized values\n",
    "df = pd.DataFrame({'AP':  [\"0m\", \"0.5m\", \"1m\"], 'FP': [\"150m\", \"250m\", \"500m\"]})\n",
    "workUnit = GeniERuntimeTaskCreator(\"ContainerHull_template.js\", df,workflow_client).get_genieruntime_work_unit(cloud_run, workspacePath)\n",
    "downloadOptions = FileOptions(\n",
    "    max_size_bytes=11124_000,\n",
    "    patterns=[\"**/T1.FEM\", \"**/*.csv\"])\n",
    "job = workflow_client.create_job(workUnit)\n",
    "\n",
    "#for debugging only\n",
    "#job_json = json.dumps(job, default=lambda o: o.encode(), indent=4)\n",
    "#print(job_json)\n",
    "await run_workflow_async(job, workflow_client, downloadOptions)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing\n",
    "The code below prints out node and element counts for the different models and present the results in a table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'local__result_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25240\\3880771431.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mlc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{local__result_path}\\\\*\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"nodeCount.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\\\'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'local__result_path' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "lc = 11\n",
    "frames = []\n",
    "for folder in glob.glob(f\"{local__result_path}\\\\*\"):\n",
    "    data = pd.read_csv(Path(folder, \"nodeCount.csv\"), index_col=0)\n",
    "    data.index = [folder.split('\\\\')[-1]]\n",
    "    frames.append(data)\n",
    "df = pd.concat(frames)\n",
    "df=df.rename_axis(\"Loadcase\")\n",
    "display(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
